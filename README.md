# Прогнозирование оттока клиентов в телекоммуникационной компании
<br>
Любой бизнес хочет максимизировать количество клиентов. Для достижения этой цели важно не только пытаться привлечь новых, но и удерживать уже существующих. 
Удержать клиента обойдется компании дешевле, чем привлечь нового. Кроме того, новый клиент может оказаться слабо заинтересованным в услугах бизнеса 
и с ним будет сложно работать, тогда как о старых клиентах уже есть необходимые данные по взаимодействию с сервисом.
<br>
Соответственно, прогнозируя отток, мы можем вовремя среагировать и попытаться удержать клиента, который хочет уйти. Опираясь на данные об услугах, 
которыми пользуется клиент, мы можем сделать ему специальное предложение, пытаясь изменить его решение об уходе от оператора. 
Благодаря этому задача удержания будет легче в реализации, чем задача привлечения новых пользователей, о которых мы еще ничего не знаем.
<br>

### Описание работы: 
Предоставлен набор данных от телекоммуникационной компании. В данных содержится информация о почти шести тысячах пользователей, их демографических характеристиках, услугах, которыми они пользуются, длительности пользования услугами оператора, методе оплаты, размере оплаты. 
<br>
Cтоит задача проанализировать данные и спрогнозировать отток пользователей (выявить людей, которые продлят контракт и которые не продлят).
<br>

### Структура данных:

#### telecom_users.csv


     customerID – id клиента
     gender – пол клиента (male/female)
     SeniorCitizen – яляется ли клиент пенсионером (1, 0)
     Partner – состоит ли клиент в браке (Yes, No)
     Dependents – есть ли у клиента иждивенцы (Yes, No)
     tenure – сколько месяцев человек являлся клиентом компании
     PhoneService – подключена ли услуга телефонной связи (Yes, No)
     MultipleLines – подключены ли несколько телефонных линий (Yes, No, No phone service)
     InternetService – интернет-провайдер клиента (DSL, Fiber optic, No)
     OnlineSecurity – подключена ли услуга онлайн-безопасности (Yes, No, No internet service)
     OnlineBackup – подключена ли услуга online backup (Yes, No, No internet service)
     DeviceProtection – есть ли у клиента страховка оборудования (Yes, No, No internet service)
     TechSupport – подключена ли услуга технической поддержки (Yes, No, No internet service)
     StreamingTV – подключена ли услуга стримингового телевидения (Yes, No, No internet service)
     StreamingMovies – подключена ли услуга стримингового кинотеатра (Yes, No, No internet service)
     Contract – тип контракта клиента (Month-to-month, One year, Two year)
     PaperlessBilling – пользуется ли клиент безбумажным биллингом (Yes, No)
     PaymentMethod – метод оплаты (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))
     MonthlyCharges – месячный размер оплаты на настоящий момент
     TotalCharges – общая сумма, которую клиент заплатил за услуги за все время
     Churn – произошел ли отток (Yes or No)

## 1. Описание данных

Выделим основные статистики числовых признаков
![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/%D1%81%D1%82%D0%B0%D1%82.%D1%87%D0%B8%D1%81%D0%BB.%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%B2.png)

Выделим основные статистики категориальных признаков
![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/%D1%81%D1%82%D0%B0%D1%82.%D0%BA%D0%B0%D1%82%D0%B5%D0%B3.%D0%BF%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%BE%D0%B2.png)

Преобразуем категориальные признаки в числовые
![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/one_hot_encoding.png)

После предварительной обработки, в данных присутствуют 5986 обьектов с 44 числовыми признаками. Признаков получилось довольно много, скорее всего присутствует много дублирующих признаков, которые появились, из-за использования функции get_dummies(). На следующем этапе исследования данных, постараемся убрать лишние, неинформативные признаки.

Выводы:
- В среднем, человек являлся клиентом компании - **32,5** месяца, медианное кол-во месяцев - **29**;
- Средний месячный размер оплаты составляет - **64.8** ед., медианное значение - **70,4** ед., минимальны размер оплаты - **18,3** ед.;
- Средняя общая сумма, которую клиент заплатил за услуги за все время - **2294,2** ед., медианное значение - **1408.6** ед.;
- Среди клиентов, неженатых мужчин немного больше, чем женщин. Немного преобладают клиенты без детей, младше пенсионного возраста, оплачивающие услуги каждый месяц;
- Большая часть клиентов не пользуется дополнительными услугами;
- Большая часть клиентов предпочитает в качестве интернет-провайдера *Fiber optic* и оплачивает услуги методом - *Electronic check*;
- У большинства клиентов подключена услуга *PhoneService*;
- Большая часть клиентов являются лояльными.


## 2. Исследование зависимостей и формулирование гипотез

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/%D1%81%D0%BE%D0%BE%D1%82%D0%BD%D0%BE%D1%88%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%BE%D0%B2.png)

На графике видно, что 73.5% пользователей являются лояльными компании, а 26.5% клиентов ушли. Присутствует ощутимый дисбаланс между двумя классами. 

#### Посмотрим на соотношение двух целевых групп в каждом из признаков
Визуализируем связи признаков с целевой переменной
![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/%D1%81%D0%BE%D0%BE%D1%82%D0%BD%D0%BE%D1%88%D0%B5%D0%BD%D0%B8%D1%8F%20%D0%B3%D1%80%D1%83%D0%BF%D0%BF.png)

Сильный дисбаланса между двумя целевыми классми, создает сложности для анализа.
Попробуем обратить внимание на обратные зависимости  с целевой переменной, которые сильнее видны.  
Из полученных гистограмм видно, что признак *tenure* имеется обратная зависимость группы оттока с группой лояльных клиентов, т.е, чем больше месяцев человек является клиентом компании, тем меньше вероятность, того, что он ее покинет.
Больше половины клиентов, которые являются пенсионерами, попадают в группу оттока. 
В группе оттока преобладают люди с типом котракта *month-to-month*.
Признак *Partner* имеет обратную корреляцию с целевой группой
Покупатели с низкими ежемесячными платежами (<30 ед.) вероятнее остануться с компанией.
Вероятность, что клиент покинет компанию выше, если интернет-провайдером клиента является *Fiber_optic*.
Отсутствие услуг: *OnlineSecurity*, *OnlineBackup*, *DeviceProtection*, *TechSupport*, *PaymentMethod_Electronic_check* делает клиента менее лояльным.

#### Визуализируем матрицу парных корреляций полученных признаков
![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/hot%20map.png)

Признаки: *OnlineBackup_No internet service*, *DeviceProtection_No internet service*, *InternetService_No*, *TechSupport_No internet service, PhoneService_No, MultipleLines_No phone service, StreamingTV_No internet service, StreamingMovies_No internet service*,  имеют множество аналогов, поэтому их можно удалить
А так же Dependents_No, PaperlessBilling_Yes имеют обратные аналоги, их тоже можно удалить

#### Выводы:
1. Были удалены признаки:
- *OnlineBackup_No internet service, DeviceProtection_No internet service, InternetService_No, TechSupport_No internet service, PhoneService_No, MultipleLines_No phone service, StreamingTV_No internet service, StreamingMovies_No internet service, Dependents_No, PaperlessBilling_Yes* - из-за наличия аналогов.

- В признаках *MonthlyCharges и TotalCharges*, аномальные значения были заменены на медианные значения.
2. Признак tenure имеет обратную зависимость с целевой переменной, чем больше месяцев человек является клиентом компании, то тем меньше вероятность того, что он ее покинет. Если клиент не покинул компанию после 5-8 месяцев обслуживания, то вероятность его ухода сильно снижается.
Если клиент покидает компанию, то он чаще состоит в браке, чем нет.
Больше половины клиентов, которые являются пенсионерами, попадают в группу оттока. Лояльность клиентов, которые начинают платить более 30 ед. за услуги, сильно падает.
Клиенты с типом котракта *month-to-month*, склонны к оттоку.
Вероятность, что клиент покинет компанию выше, если интернет-провайдером клиента является *Fiber_optic*.
Отсутствие услуг: *OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, InternetService_Fiber_optic, PaymentMethod_Electronic_check* делает клиента менее лояльным.
Последние два заключения являются спорными, так как у большинства клиентов интернет-провайдером является Fiber_optic и не подключены дополнительные услуги.
В принципе, навязывание дополнительных услуг не добавляет лояльности клиентам, так что позже, проверим эти утверждения.

3. В целом, наличие корреляционых связей между целевой переменной и признаками выглядит слабым. Попробуем использовать два подхода к построению моделей.
1 подход: возьмем линейные модели, особенно *LogisticRegression*(если линейная связь все же есть) и *Lasso* (которая, удалит лишние признаки). С помощью *PolynomialFeatures* создадим новую матрицу признаков, состоящую из всех полиномиальных комбинаций признаков со степенью 2. Возможно это усилит связи между данными.
2 подход: используем нелинейные модели, knn и метод ближайших соседей, которые хорошо подходят для решения задач классификации. Используем: *Градиентный бустинг*, *Экстремальный градиентный бустинг*, *Байясовский классификатор* и т.д. С помощью *Feature Importance* определим наиболее важные признаки.
Для сравнения моделей между собой будем использовать метрику ROC-AUC, т.к она позволяет объективно сопоставить уровень качества разных моделей классификации, решающих одну и ту же задачу, но обученных на разных данных.

## 3. Построение моделей для прогнозирования оттока
Так как матрица корреляций показала слабые линейные зависимости между признаками и целевой переменной, преобразуем векторы признаков в пространство с большим количеством измерений
Сгенерируем новую матрицу признаков, состоящей из всех полиномиальных комбинаций признаков с мах степенью 2 с помощью *PolynomialFeatures*

Выберем следуюшие модели: *Логистическая регрессия*, *Гребневая регрессия*, *Лассо*, *Линейная регрессия*

LogisticRegression {'C' : range(1, 10), 'penalty': ['l1', 'l2'] }

StratifiedKFold(n_splits=5, random_state=17, shuffle=True)

Lasso_cv = LassoCV(alphas=[0.01], cv = skf, max_iter = 100000)

Ridge {'alpha': np.arange(0.1, 10.0, 0.1)}

Оптимизируем параметры моделей с помощью GridSearchCV, обучим модели с помощью кросс-валидации(scoring='roc_auc', cv=5) и получим список значений долей уверенности моделей


#### Таблица метрики AUC ROC моделей
![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/AUC%20%D0%BB%D0%B8%D0%BD%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB.png)

Лучший результат показала Лассо регуляризация (AUC ROC = 0.85), на которую возлагались надежды, из за большого кол-ва признаков, которые образовались за счет появления их полиномиальных комбинаций.

#### Подберем признаки для нелинейных моделей

Отберем признаки с помощью модели xgboost представим данные в виде обьекта DMatrix 
F-score признаков, которая вычисляется на основе того, как часто делалось разбиение по данному признаку

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/feature%20imp.png)

признаки которые используются больше всего, которые важны для обучения моделей:

4, 3, 5, 18, 17, 24, 19, 32, 10, 21, 8, 29, 31, 26, 1, 13, 6, 0, 22

Выберем следуюшие модели: *GradientBoosting*, *XGBClassifier*, *Метод К-ближайших соседей*, *Метод опорных векторов*, *GaussianNB*

GradientBoostingClassifier {'n_estimators': np.arange(10, 100, 10), 
                            'max_depth': np.arange(2, 10, 2),
                            'learning_rate': np.arange(0.1, 0.3, 0.1)} 

XGBClassifier              {'n_estimators': np.arange(10, 100, 10),
                            'max_depth': np.arange(2, 10, 2),
                            'learning_rate': np.arange(0.1, 0.3, 0.1),
                            'scale_pos_weight':[3]} 

KNeighborsClassifier {'n_neighbors' : range(1, 10)} 
SVC {'degree' : range(1, 10), 'probability': [True]} 

Оптимизируем параметры моделей с помощью GridSearchCV, обучим модели с помощью кросс-валидации(scoring='roc_auc', cv=5) и получим список значений долей уверенности моделей

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/AUC%20%D0%BD%D0%B5%20%D0%BB%D0%B8%D0%BD%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B5%D0%B9.png)

Так же попробуем обьединить алгоритмы в модель стекинга с целью попытаться улчшить метрику качества
Мета-моделью будет модель с самым высоким показателем метрики GBC

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/AUC%20%D0%A1%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3.png)

Стекинг показал невысокий результат результат (AUC ROC = 0.797). Лучший результат среди линейных моделей показала Лассо регуляризация (AUC ROC = 0.846), абсолютно лучший результат среди линейных и нелинейных моделей показал Градиентный бустинг (AUC ROC = 0.848).Градиентный бустинг в 85% случаев предсказал правильный класс обьекта, а в 15% случаев предсказанный класс оказался противоположным(доля классов TPR(True Positive Rate) = 0.85, FPR(False Positive Rate) = 0.15). 

## 4. Сравнение качества моделей 
Получим предсказания моделей на тестовой выборке, а так же значения показателей точности(Precision) и полноты(Recall). Т.к. в рамках текущей задачи важно определить как можно больше клиентов, которые могут уйти и не так страшно будет, если лояльные клиенты будут ошибочно приняты за уходящих, то показатель Полноты(Recall) будет для нас приорететным.

**Метрики качества нелинейных моделей**

Визуализируем матрицы ошибок

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/confus_mtx%20%D0%BD%D0%B5%20%D0%BB%D0%B8%D0%BD.png)

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/roc%20pr%20%D0%BD%D0%B5%D0%BB%D0%B8%D0%BD.png)

Модели: XGBoost, Байесовский классификатор и Стекинг, показали самые высокие  показатели метрик AUC ROC, Recall(Полнота) и низкими показателями ложноотрицательных значений.

**Метрики качества линейных моделей**

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/confus_mtx%20%D0%BB%D0%B8%D0%BD.png)

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/roc%20pr%20%D0%BB%D0%B8%D0%BD.png)

Модель Лассо показала самую высокую значение мктрики (AUC ROC=0.84), но довольно низкий показатель полноты(Recall=0.44), что плохо для решения текущей задачи, поэтому эта модель проигрывает моделе XGBoost. В целом, модели Ридж и Лассо показали очень высокие показатели метрики AUC. Но, к сожалению, эти модели имеют высокие показатели ложно-отрицательных значений, т.е модели упускают клиентов собирающихся уйти.

### Вывод:
Модель XGBoost имеет самую высокую метрику качества (AUC ROC=0.76) среди нелинейных моделей, а так же самый высокий показатель полноты(Recall=0.81). Метрика полноты означает наибольшую долю клиентов, по сравнению с другими моделями, для которых был верно определен класс. Матрицы ошибок моделей, так же, показывают, что у модели XGBoost, кол-во ложноотрицательных значений (количество клиентов, которые могут уйти, но ошибочно принятых за лояльных)(FN = 60) меньше, чем у других моделей, что так же важно для решения задачи. Высокое количество ложноположительных значений(количество лояльных клиентов, отнесенных к классу оттока)(FP=263), не так страшно и даже заставляет обратить на них внимание. Возможно, это те клиенты, которые могут расторгнуть договор в ближайшем будущем.
Поэтому, с помощью модели XGBoost попробуем определить какие именно клиенты способны уйти. Для этого снова обучим отобранную модель на всех данных(что конечно не совсем корректно, так как модель 'видела' часть данных, но возможно,  модель сможет 'засомневаться' в текущей оценке статуса клиента. Отберем только тех клиентов, которые, как считает модель, способны уйти. Исследуем распределение целевых классов в признаках этих клиентов. 

#### Определим конкретных клиентов, которые могут покинуть компанию в ближайшем будущем
Получим вероятностные оценки нашей модели

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/predict%20proba.png)
 
Выделим всех клиентов, которых модель отнесла к классу оттока (True Negative + False Positive)

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/predict%201.png)

Построим визуализацию для прогнозируемых классов оттока True Negative + False Positive

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/feature%20importance.png)

Соотношение лояльных клиентов и ушедших примерно одинаково. По данным видно, что различия между двумя группами имеют признаки: *PaymentMethod, MonthlyCharges, TotalCharges, tenure*. Значит, в основном, по этим признакам модель и разделяла клиентов по классам.
Различия соотношений разных классов в признаках, не велико, т.е модель считает клиентов, которые пока попали в группу лояльных - клиентами, которые похожи на тех, кто может покинуть компанию в будущем.

Выделим клиентов потенциально способных прекратить сотрудничество в будущем.

![alt text](https://github.com/Lvdmv/Coursework_ML/blob/main/img%20churn/churn%20clients.png)

#### ВЫВОДЫ:
- Лучшей моделью выбран *XGBoost*. Он имеет самую высокую метрику качества (AUC ROC=0.76), а так же самый высокий показатель полноты(Recall=0.81). 

- Использованиеи линейных моделей - было хорошей практикой. Получились неплохие результаты. Но, к сожалению, в рамках данной задачи, линейные модели подходят хуже.

- признак *tenure* имеет обратную зависимость группы оттока с группой лояльных клиентов. Если человек является клиентом компании более 5 мес., то вероятность его ухода сильно снижается.

- Отсутствие техподдержки, а так же метод оплаты электронным чеком, влияют на отток.

- Гипотеза о том, что клиенты с низкими ежемесячными платежами (<30 ед.) вероятнее остануться с компанией, не является истинной, так как наибольший отток клиентов происходит при размере ежемесячного платежа - от примерно 70 до 95 ед. 

- Обратная корреляция признака Partner, а так же признаки *OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, PaymentMethod_Electronic_check*, тип контракта *Month-to-month*, интернет-провайдер *Fiber optic*,  не влияют на отток.
- Мы провели испытание модели на всех данных. Модель считает, что:

 - 1310 клиентов могут расторгнуть договор в ближайшем будущем. 

 - 3122 клиентов, которые скорее всего продлят контракт.

К вопросу о целесообразности проведения иследования оттока клиентов на всех данных: 

Ранее, модель на тестовых данных показала, что 620 клиентов готовы остаться, а 267 могут покинуть компанию. В последствии, модель была обучена так же на 80% от всех данных, но предсказания делала уже на всех данных. И не смотря на это, пересмотрела статус еще 1043 клиентов, переведя их из категории лояльных, к категории возможного оттока.
